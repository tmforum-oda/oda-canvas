# prometheus-values.yaml
# Values file for kube-prometheus-stack to monitor ODA Canvas components
# This configuration enables monitoring of ODA Components deployed in the 'components' namespace

# Global RBAC configuration
rbac:
  create: true

prometheus:
  prometheusSpec:
    # ServiceMonitor namespace selector - tells Prometheus operator which namespaces to look for ServiceMonitor resources
    # This allows automatic discovery of services that have ServiceMonitor resources defined
    serviceMonitorNamespaceSelector: {}  # Empty selector allows Prometheus to discover ServiceMonitors in all namespaces
    serviceMonitorSelector: {}           # Empty selector allows Prometheus to scrape all ServiceMonitors it discovers
    
    # Enable ServiceMonitor selection from all namespaces
    serviceMonitorSelectorNilUsesHelmValues: false  # Don't restrict ServiceMonitor selection to Helm values
    
    # Ensure Prometheus can monitor the components namespace
    ruleNamespaceSelector: {}            # Allow rules from all namespaces
    ruleSelectorNilUsesHelmValues: false # Don't restrict rule selection to Helm values
    
    # Enable logging to help debug ServiceMonitor discovery
    logLevel: info
    
    # Retention and storage settings
    retention: 15d
    
    # Security context to ensure proper permissions
    securityContext:
      fsGroup: 65534
      runAsUser: 65534
      runAsNonRoot: true
      
    # Additional service account annotations if needed
    serviceAccountAnnotations: {}
    
    # Ensure Prometheus can access all namespaces for ServiceMonitor discovery
    clusterRole: true
    
    # Additional scrape configurations for direct pod and service discovery
    # These are added to Prometheus configuration for more granular control over what gets monitored
    additionalScrapeConfigs:
      # Job to scrape metrics from pods in the components namespace
      # This configuration looks for pods with specific Prometheus annotations
      - job_name: 'components-pods'
        kubernetes_sd_configs:
          - role: pod  # Use Kubernetes service discovery to find pods
            namespaces:
              names:
                - components  # Only look in the components namespace
        relabel_configs:
          # Only scrape pods that have the annotation "prometheus.io/scrape: true"
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          # Use custom metrics path if specified in annotation "prometheus.io/path"
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          # Use custom port if specified in annotation "prometheus.io/port"
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          # Add all pod labels as metrics labels (with kubernetes_pod_label_ prefix)
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          # Add namespace name as a label
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          # Add pod name as a label
          - source_labels: [__meta_kubernetes_pod_name]
            action: replace
            target_label: kubernetes_pod_name
            
      # Job to scrape metrics from services in the components namespace
      # Similar to pod scraping but targets Kubernetes services instead
      - job_name: 'components-services'
        kubernetes_sd_configs:
          - role: service  # Use Kubernetes service discovery to find services
            namespaces:
              names:
                - components  # Only look in the components namespace
        relabel_configs:
          # Only scrape services that have the annotation "prometheus.io/scrape: true"
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          # Use custom metrics path if specified in annotation "prometheus.io/path"
          - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          # Use custom port if specified in annotation "prometheus.io/port"
          - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
          # Add all service labels as metrics labels (with kubernetes_service_label_ prefix)
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          # Add namespace name as a label
          - source_labels: [__meta_kubernetes_namespace]
            action: replace
            target_label: kubernetes_namespace
          # Add service name as a label
          - source_labels: [__meta_kubernetes_service_name]
            action: replace
            target_label: kubernetes_service_name
            
  # Service account configuration
  serviceAccount:
    create: true
    annotations: {}
    
  # RBAC configuration to allow Prometheus to access components namespace
  rbac:
    create: true

# Global namespace override - allows monitoring across all namespaces if set to a specific namespace
# Empty string means no override, using default namespace behavior
namespaceOverride: ""

# Node Exporter configuration - collects hardware and OS metrics from cluster nodes
# Disabled due to mount propagation issues in some environments (Docker Desktop, WSL)
nodeExporter:
  enabled: false  # Set to true if you want host-level metrics and your environment supports it

# Grafana configuration - provides web-based dashboards for visualizing metrics
grafana:
  enabled: true  # Enable Grafana deployment as part of the monitoring stack
  
  # Dashboard providers configuration - defines how Grafana loads dashboards
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'           # Provider name
        orgId: 1                  # Grafana organization ID
        folder: ''                # Folder in Grafana UI (empty = root)
        type: file                # Dashboard source type (file-based)
        disableDeletion: false    # Allow dashboards to be deleted from UI
        editable: true            # Allow dashboards to be edited from UI
        options:
          path: /var/lib/grafana/dashboards/default  # Path where dashboards are stored
  
  # Dashboard definitions - actual dashboard JSON files would be defined here
  dashboards:
    default:
      # Add any ODA-specific dashboards here
      # Example:
      # oda-component-overview:
      #   json: |
      #     { "dashboard": { ... } }
      
# ServiceMonitor configuration - defines how the Prometheus operator discovers services to monitor
# ServiceMonitor is a custom resource that tells Prometheus which services to scrape
serviceMonitor:
  enabled: true          # Enable ServiceMonitor resource creation
  namespace: components  # Namespace where ServiceMonitors will be created
  selector: {}          # Empty selector means match all services in the namespace
                        # Could be configured to match specific labels like:
                        # selector:
                        #   matchLabels:
                        #     app.kubernetes.io/part-of: oda-canvas

# Create a troubleshooting script to debug ServiceMonitor discovery
# A debug script (debug-servicemonitor.sh) should be created in the same directory
# to help diagnose ServiceMonitor discovery issues

# Usage Notes:
# 1. To monitor ODA components, they should have these annotations:
#    - prometheus.io/scrape: "true"    # Enable scraping
#    - prometheus.io/port: "8080"      # Port where metrics are exposed
#    - prometheus.io/path: "/metrics"  # Path to metrics endpoint (optional, defaults to /metrics)
#
# 2. To deploy this configuration:
#    helm upgrade monitoring prometheus-community/kube-prometheus-stack -n monitoring -f ./prometheus-values.yaml
#
# 3. IMPORTANT: For ServiceMonitor discovery to work, ensure the components namespace has proper labels:
#    kubectl label namespace components name=components
#    kubectl label namespace components prometheus.io/scrape=true
#
# 4. Verify ServiceMonitor discovery:
#    kubectl get servicemonitors -n components
#    kubectl logs -n monitoring -l app.kubernetes.io/name=prometheus
#
# 5. Access Grafana dashboard:
#    kubectl port-forward svc/monitoring-grafana 3000:80 -n monitoring
#    Then visit http://localhost:3000 (admin/prom-operator by default)
#
# 6. Access Prometheus UI:
#    kubectl port-forward svc/monitoring-kube-prometheus-prometheus 9090:9090 -n monitoring
#    Then visit http://localhost:9090
#
# 7. Check if your ServiceMonitor is being discovered:
#    - Go to Prometheus UI → Status → Targets
#    - Look for serviceMonitor/components/r1-productcatalogmanagement-metrics/0
#
# 8. Troubleshooting ServiceMonitor not appearing in targets:
#    FIRST: Run the debug script: ./debug-servicemonitor.sh
#    
#    Common issues and solutions:
#    a) Missing service with correct label:
#       kubectl get svc -n components -l name=r1-productcatalogmanagement-sm
#       If no service found, check the ServiceMonitor selector matches actual service labels
#    
#    b) Namespace not accessible to Prometheus:
#       kubectl label namespace components name=components
#       kubectl auth can-i get servicemonitors --namespace=components --as=system:serviceaccount:monitoring:monitoring-kube-prometheus-prometheus
#    
#    c) Prometheus operator not configured to discover ServiceMonitors:
#       Ensure serviceMonitorSelectorNilUsesHelmValues: false in prometheus.prometheusSpec
#    
#    d) RBAC issues - check if Prometheus has permissions:
#       kubectl get clusterrole monitoring-kube-prometheus-prometheus
#       kubectl get clusterrolebinding monitoring-kube-prometheus-prometheus
#    
#    e) Force configuration reload:
#       kubectl delete pod -n monitoring -l app.kubernetes.io/name=prometheus
#       kubectl rollout restart statefulset/prometheus-monitoring-kube-prometheus-prometheus -n monitoring
#    
#    f) Check if ServiceMonitor endpoint is reachable:
#       kubectl port-forward svc/r1-productcatalogmanagement-sm 4000:4000 -n components
#       curl http://localhost:4000/r1-productcatalogmanagement/metrics